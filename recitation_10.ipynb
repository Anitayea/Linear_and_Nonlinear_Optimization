{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "recitation 10.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anitayea/Linear_and_Nonlinear_Optimization/blob/recitations/recitation_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recitation 10\n",
        "\n",
        "\n",
        "*   Finish Midterm review\n",
        "*   Quiz 7 review\n",
        "*   Quiz 8 review\n",
        "\n"
      ],
      "metadata": {
        "id": "xIN2oMjdclYP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. \n",
        "(b) \n",
        "Primal\n",
        "\\begin{align*}\n",
        "\\min_{ \\beta \\in R^k\\\\ a_i\\in R} \\sum_i a_i\\\\\n",
        "\\text{s.t. } a_i \\geq y_i - x_i^T\\beta\\\\\n",
        "a_i \\geq x_i^T\\beta - y_i\n",
        "\\end{align*}\n",
        "\n",
        "Lagrangian\n",
        "\\begin{align*}\n",
        "L(\\beta,a; c,d) &= \\sum_i a_i - \\sum_i c_i[a_i-(y_i-x^T_i\\beta)] - \\sum_i d_i[a_i-(x_i^T\\beta - y_i)] \\\\\n",
        "&= \\sum_i (c_i - d_i)y_i - \\sum_i a_i(1-c_i-d_i) - \\beta\\sum_i x_i(d_i - c_i)\n",
        "\\end{align*}\n",
        "\n",
        "dual\n",
        "\\begin{align*}\n",
        "\\max_{ c_i,d_i \\geq 0} \\sum(c_i-d_i)y_i = (c-d)^Ty\\\\\n",
        "\\text{s.t. } 1 -c_i - d_i = 1 - c- d = 0\\\\\n",
        "x_i(d_i-c_i) = (d-c)^Tx = 0\n",
        "\\end{align*}\n",
        "\n",
        "(c) yes - it is a linear programming problem and the primal had a finite solution.\n",
        "\n",
        "Recall the only time when strong duality doesn't hold for a linear programming problem is when one solution is $+\\infty$ and the other is $-\\infty$"
      ],
      "metadata": {
        "id": "md55t__Vhr9d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. \n",
        "The matrix is 4x4\n",
        "(a) player 1 has choices: $p_1q_1$, $p_1q_2$, $p_2q_1$, and $p_2q_2$\n",
        "player 2 has choices: $p_1$, $p_2$, $q_1$, and $q_2$\n",
        "\n",
        "The following matrix is with player 1 choosing the row, and player 2 choosing the column with choices in the order above\n",
        "\n",
        "[[-2, 0, -2, 0][-1, 0, 0, -1][0, -3, -3, 0][0, -4, 0 ,-4]]\n",
        "\n",
        "(b) see notebook code"
      ],
      "metadata": {
        "id": "_HWA2wpvn772"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.\n",
        "see notebook"
      ],
      "metadata": {
        "id": "pshh60MWlY9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quiz 7\n",
        "\n",
        "1. [T/F] Let $f:\\Omega \\rightarrow R$ be a continuous function, where $%\n",
        "\\Omega \\subseteq R^{d}$, and consider \n",
        "\\begin{equation*}\n",
        "\\min_{x\\in \\Omega }f\\left( x\\right) \n",
        "\\end{equation*}\n",
        "\n",
        "A sufficient condition that a minimum $x^{\\ast }\\in \\Omega $ exists is that $%\n",
        "\\Omega $ is closed.\n",
        "\n",
        "ANSWER:FALSE - $f(x) = -1/x$ on $[0,1]$ the min is unbounded but never acheived because $f(0)$ is undefined\n",
        " \n",
        " ---\n",
        "\n",
        "2. [T/F] Consider $\\Omega =\\left\\{ \\left( x,y\\right) \\in R^{2}:x+y\\leq\n",
        "1\\right\\} $. Then $(-1/2,1/3)$ is a feasible direction for $\\left(\n",
        "1/2,1/2\\right) $.\n",
        "\n",
        "ANSWER: We are on the boundary, $.5+.5 = 1$, TRUE because $x+tu$ is in the set for all $t\\geq 0$\n",
        "\n",
        "---\n",
        "\n",
        "3. [T/F] Let $f:\\Omega \\rightarrow R$ be a $C^{2}$ function, where $\\Omega\n",
        "\\subseteq R^{2}$, and consider \n",
        "\\begin{equation*}\n",
        "\\min_{x\\in \\Omega }f\\left( x\\right) \n",
        "\\end{equation*}\n",
        "\n",
        "Let $x^{\\ast }$ be an interior point of $\\Omega $. Assume $\\nabla f\\left(\n",
        "x^{\\ast }\\right) =0$ and \n",
        "\\begin{equation*}\n",
        "D^{2}f\\left( x^{\\ast }\\right) =%\n",
        "\\begin{pmatrix}\n",
        "1 & 3 \\\\ \n",
        "3 & 2%\n",
        "\\end{pmatrix}%\n",
        ".\n",
        "\\end{equation*} \n",
        "Then $x^{\\ast }$ is a local minimum of $f$.\n",
        "\n",
        "ANSWER: FALSE\n",
        "\n",
        "aside - checking for positive semi-definite \n",
        "\n",
        "def: $\\forall x \\quad x^TQx \\geq 0$ but this can be hard to prove directly. What we can do instead is prove using a basis for $x$. Or, especial for the 2d case, we can just compute the eigenvalues. If they are all non-negative then we know that the matrix is positive semi-definite.\n",
        "\n",
        "So in this example, the trace is 3, and the determinant is -7. Thus our eigenvalues satisfy: $\\lambda_1 + \\lambda_2 = 3$ and $\\lambda_1\\lambda_2 = -7$. Clearly from the last equation we know that there must be negative eigenvalue.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "A6BsE6Sgssvm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. [T/F] Let $\\Omega =\\left\\{ \\left( x,y\\right) \\in R^{2}:x+y\\leq 1\\right\\} $\n",
        "and consider  $f\\left( x\\right) =x_{1}+2x_{2}-5x_{1}^{2}-4x_{2}^{2}$. Then $%\n",
        "\\left( 0,0\\right) $ is a local minimum of $f$ on $\\Omega $.\n",
        "\n",
        "ANSWER: FALSE - \n",
        "\n",
        "$\\frac{\\partial f}{\\partial x_1} = 1 - 10x_1$\n",
        "\n",
        "\n",
        "$\\frac{\\partial f}{\\partial x_2} = 2 - 8x_2$\n",
        "\n",
        "$\\nabla f$ evaluated at $(0,0)$ we get $(1,2)\\not = 0$\n",
        "\n",
        "---\n",
        "\n",
        "5. [MC] Let $f:\\Omega \\rightarrow R$ be a $C^{1}$ function, where $\\Omega\n",
        "\\subseteq R^{d}$, and consider \n",
        "\\begin{equation*}\n",
        "\\min_{x\\in \\Omega }f\\left( x\\right) \n",
        "\\end{equation*}\n",
        "\n",
        "Let $x^{\\ast }$ be an interior point of $\\Omega $. The condition $\\nabla\n",
        "f\\left( x^{\\ast }\\right) =0$ is\n",
        "\n",
        "(i) A necessary, but not a sufficient condition that $x^{\\ast }$ is a local\n",
        "minimum of $f$ on $\\Omega $.\n",
        "\n",
        "(ii) A sufficient, but not a necessary condition that $x^{\\ast }$ is a\n",
        "local minimum of $f$ on $\\Omega $.\n",
        "\n",
        "(iii) A necessary and sufficient condition that $x^{\\ast }$ is a local\n",
        "minimum of $f$ on $\\Omega $.\n",
        "\n",
        "(iv) Neither a necessary, nor a sufficient condition that $x^{\\ast }$ is a\n",
        "local minimum of $f$ on $\\Omega $.\n",
        "\n",
        "ANSWER: (i) - not enough to show that gradient is 0, may be a local max for example\n",
        "\n",
        "---\n",
        "\n",
        "6. [Numerical answer] Consider $\\Omega =\\left\\{ \\left( x_{1},x_{2}\\right)\n",
        "\\in R^{2}:x_{1}+x_{2}\\geq 1\\right\\} $ and $f\\left( x\\right)\n",
        "=x_{1}^{2}+x_{2}^{2}$. What is the value $V$ given by \n",
        "\\begin{equation*}\n",
        "V=\\min_{x\\in \\Omega }f\\left( x\\right) .\n",
        "\\end{equation*}\n",
        "\n",
        "ANSWER: $\\frac{1}{2} = 0.5$\n",
        "\n",
        "We know we must be on the line $x_1+x_2 = 1$ so we can instead solve $\\min x_1^2 + (1-x_1)^2$ we can do this by taking the first derivate and setting it equal to 0. We get $2x_1 - 2(1-x_1) \\implies 4x_1 = 2 \\implies x_1 = 0.5 = x_2$"
      ],
      "metadata": {
        "id": "V-tMNyMIwz5N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## quiz 8\n",
        "1. [T/F] A strictly convex function $\\mathbb{R}^{d}\\rightarrow \\mathbb{R}$\n",
        "has always a minimizer $x$ on $\\mathbb{R}$.\n",
        "\n",
        "ANSWER: FALSE - similar to a question from last quiz, we can have that the function goes to infinity. For example $\\sum_{i=1}^d e^{x_i}$\n",
        "\n",
        "---\n",
        "\n",
        "2. [T/F] Let $u\\in \\mathbb{R}^{d}$, $d\\geq 2$. The function $f\\left(\n",
        "x\\right) =\\frac{1}{2}x^{\\top }uu^{\\top }x$ is strictly convex on $\\mathbb{R}^{d}$.\n",
        "\n",
        "ANSWER: FALSE - The hessian at any $x$ is $uu^T$ which is positive semidefinite but not necessarily positive definite\n",
        "\n",
        "---\n",
        "\n",
        "3.  [T/F] The gradient descent method seen in class always always decreases the objective function.\n",
        "\n",
        "ANSWER: True - because in class upto when the quiz was posted, we set $\\alpha_k$ as to minimize (I will get back to you on this one). \n",
        "\n",
        "What about if $f$ is a constant function? what about need for Armijo?\n",
        "\n",
        "--- \n",
        "\n",
        "4. [MC] Consider $f:\\mathbb{R}^{d}\\rightarrow \\mathbb{R}$ a smooth convex\n",
        "function defined on the whole of $\\mathbb{R}^{d}$. \n",
        "\n",
        "The condition $\\nabla f\\left( x\\right) =0$ is:\n",
        "\n",
        "(i) necessary and sufficient to the fact that $x$ is a local minimizer of $f\n",
        "$ on $\\mathbb{R}^{d}$\n",
        "\n",
        "(ii) necessary but not sufficient to the fact that $x$ is a local minimizer\n",
        "of $f$ on $\\mathbb{R}^{d}$\n",
        "\n",
        "(iii) sufficient but not necessary to the fact that $x$ is a local\n",
        "minimizer of $f$ on $\\mathbb{R}^{d}$\n",
        "\n",
        "(iv) neither sufficient, nor necessary to the fact that $x$ is a local\n",
        "minimizer of $f$ on $\\mathbb{R}^{d}$\n",
        "\n",
        "ANSWER: (i)\n",
        "\n",
        "---\n",
        "\n",
        "5. Consider a matrix $Q$ whose smallest eigenvalue is $0.1$ and whose largest eigenvalue is $10$.\n",
        "\n",
        "With the same notations as those used in class, what is the upper bound on $%\n",
        "E\\left( y_{k+1}\\right) /E\\left( y_{k}\\right) $ implied by Kantorovich's\n",
        "inequality? (truncate your anwer to two decimal places)\n",
        "\n",
        "ANSWER: $(10-0.1)^2 / (10+0.1)^2 = 0.96$"
      ],
      "metadata": {
        "id": "OA0BpOYjz35r"
      }
    }
  ]
}